{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import time \n",
    "import os \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('/home/jabed/Downloads/Desktop_backup/Desk1/ML_tensor_pytorch/MultilabelClassification/Tensorlfow/IRIS.csv')\n",
    "\n",
    "#data=pd.get_dummies(data,columns=['species'])\n",
    "df=data\n",
    "species = dict(zip(list(df['species'].unique()), ([0, 1, 2])))\n",
    "df['species'].replace(species,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('species',axis=1)\n",
    "Y=df['species'].values\n",
    "y_dummy=pd.get_dummies(Y)\n",
    "X=X.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(X,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(tf.keras.layers.Layer):\n",
    "    def __init__(self,units=1):\n",
    "        super(Linear,self).__init__()\n",
    "        self.units=units\n",
    "    def build(self,input_shape):\n",
    "        self.weight=self.add_weight(\n",
    "            shape=(input_shape[-1],self.units),\n",
    "            initializer='random_normal',\n",
    "            trainable=True,\n",
    "\n",
    "        )    \n",
    "        self.bias = self.add_weight(\n",
    "            shape=(self.units,), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "    def call(self,inputs):\n",
    "        return tf.matmul(inputs,self.weight)+self.bias \n",
    "    def get_config(self):\n",
    "        return {'units':self.units}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabel(tf.keras.Model):\n",
    "    def __init__(self,num_class):\n",
    "        super(MultiLabel,self).__init__()\n",
    "\n",
    "\n",
    "        self.linear=Linear(num_class)\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        l1=self.linear(inputs)\n",
    "        out=tf.nn.sigmoid(l1)\n",
    "        return out \n",
    "    def accuracy(self,y_dummy,y_pred):\n",
    "        acc=tf.keras.metrics.Accuracy()\n",
    "        acc.update_state(y_dummy,tf.argmax(y_pred,axis=1))    \n",
    "        return acc.result().numpy()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MultiLabel(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1,\n",
       "       1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=tf.keras.losses.CategoricalCrossentropy()\n",
    "logits=model.call(X)\n",
    "loss_value=loss_fn(y_dummy,logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X_train,y_train,num_epochs=100,lr=0.01,y_dummy=y_dummy):\n",
    "    start=time.time()\n",
    "\n",
    "    j_history=[]\n",
    "    loss_fn=tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    for epoch in range(num_epochs+1):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits=model.call(X_train)\n",
    "            loss_value=loss_fn(y_dummy,logits)\n",
    "\n",
    "\n",
    "        grads=tape.gradient(loss_value,model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads,model.trainable_weights))\n",
    "        acc=model.accuracy(y_train,logits)\n",
    "        j_history.append((loss_value.numpy(),acc))\n",
    "\n",
    "        if epoch %10==0:\n",
    "            print('epoch {} loss {:.4f} and accuracy {:.4f}'.format(epoch,loss_value.numpy(),acc))   \n",
    "            #print(tf.argmax(logits[0:20],axis=1))  \n",
    "\n",
    "    end=time.time()\n",
    "    print('totla time = ',end-start)\n",
    "    return np.array(j_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 1.0628 and accuracy 0.6333\n",
      "epoch 10 loss 0.9413 and accuracy 0.6600\n",
      "epoch 20 loss 0.8104 and accuracy 0.6667\n",
      "epoch 30 loss 0.6983 and accuracy 0.6667\n",
      "epoch 40 loss 0.6145 and accuracy 0.6667\n",
      "epoch 50 loss 0.5523 and accuracy 0.7533\n",
      "epoch 60 loss 0.5047 and accuracy 0.8667\n",
      "epoch 70 loss 0.4670 and accuracy 0.9267\n",
      "epoch 80 loss 0.4361 and accuracy 0.9400\n",
      "epoch 90 loss 0.4100 and accuracy 0.9533\n",
      "epoch 100 loss 0.3875 and accuracy 0.9667\n",
      "totla time =  2.7951791286468506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.0628146 , 0.6333333 ],\n",
       "       [1.0501735 , 0.55333334],\n",
       "       [1.0384269 , 0.45333335],\n",
       "       [1.0270599 , 0.38      ],\n",
       "       [1.0155518 , 0.39333335],\n",
       "       [1.0037714 , 0.44666666],\n",
       "       [0.9917168 , 0.52      ],\n",
       "       [0.97941   , 0.56666666],\n",
       "       [0.96687865, 0.64666665],\n",
       "       [0.954151  , 0.66      ],\n",
       "       [0.94125456, 0.66      ],\n",
       "       [0.92821836, 0.66      ],\n",
       "       [0.9150729 , 0.6666667 ],\n",
       "       [0.90185076, 0.6666667 ],\n",
       "       [0.88858783, 0.6666667 ],\n",
       "       [0.8753223 , 0.6666667 ],\n",
       "       [0.862094  , 0.6666667 ],\n",
       "       [0.848944  , 0.6666667 ],\n",
       "       [0.8359121 , 0.6666667 ],\n",
       "       [0.8230367 , 0.6666667 ],\n",
       "       [0.8103517 , 0.6666667 ],\n",
       "       [0.79788744, 0.6666667 ],\n",
       "       [0.7856686 , 0.6666667 ],\n",
       "       [0.7737152 , 0.6666667 ],\n",
       "       [0.762042  , 0.6666667 ],\n",
       "       [0.75065947, 0.6666667 ],\n",
       "       [0.7395746 , 0.6666667 ],\n",
       "       [0.7287912 , 0.6666667 ],\n",
       "       [0.7183109 , 0.6666667 ],\n",
       "       [0.7081337 , 0.6666667 ],\n",
       "       [0.69825757, 0.6666667 ],\n",
       "       [0.68867856, 0.6666667 ],\n",
       "       [0.6793907 , 0.6666667 ],\n",
       "       [0.67038673, 0.6666667 ],\n",
       "       [0.661658  , 0.6666667 ],\n",
       "       [0.6531952 , 0.6666667 ],\n",
       "       [0.644989  , 0.6666667 ],\n",
       "       [0.63702995, 0.6666667 ],\n",
       "       [0.6293083 , 0.6666667 ],\n",
       "       [0.6218154 , 0.6666667 ],\n",
       "       [0.61454284, 0.6666667 ],\n",
       "       [0.60748273, 0.6666667 ],\n",
       "       [0.6006272 , 0.6666667 ],\n",
       "       [0.59396875, 0.6666667 ],\n",
       "       [0.5875    , 0.6666667 ],\n",
       "       [0.5812136 , 0.67333335],\n",
       "       [0.5751029 , 0.70666665],\n",
       "       [0.56916106, 0.70666665],\n",
       "       [0.5633814 , 0.7133333 ],\n",
       "       [0.55775774, 0.73333335],\n",
       "       [0.5522842 , 0.75333333],\n",
       "       [0.5469552 , 0.76666665],\n",
       "       [0.5417651 , 0.7733333 ],\n",
       "       [0.5367088 , 0.8       ],\n",
       "       [0.53178126, 0.82      ],\n",
       "       [0.5269777 , 0.8333333 ],\n",
       "       [0.5222932 , 0.8333333 ],\n",
       "       [0.51772326, 0.8333333 ],\n",
       "       [0.5132634 , 0.84      ],\n",
       "       [0.50890946, 0.86      ],\n",
       "       [0.5046574 , 0.8666667 ],\n",
       "       [0.50050324, 0.88      ],\n",
       "       [0.49644333, 0.8933333 ],\n",
       "       [0.49247438, 0.9066667 ],\n",
       "       [0.48859283, 0.9066667 ],\n",
       "       [0.48479554, 0.9066667 ],\n",
       "       [0.48107937, 0.91333336],\n",
       "       [0.4774412 , 0.92      ],\n",
       "       [0.47387838, 0.9266667 ],\n",
       "       [0.47038803, 0.9266667 ],\n",
       "       [0.46696746, 0.9266667 ],\n",
       "       [0.46361426, 0.9266667 ],\n",
       "       [0.46032593, 0.9266667 ],\n",
       "       [0.4571002 , 0.93333334],\n",
       "       [0.45393485, 0.93333334],\n",
       "       [0.45082778, 0.93333334],\n",
       "       [0.44777694, 0.93333334],\n",
       "       [0.44478044, 0.93333334],\n",
       "       [0.44183645, 0.93333334],\n",
       "       [0.4389431 , 0.94      ],\n",
       "       [0.43609878, 0.94      ],\n",
       "       [0.4333019 , 0.94      ],\n",
       "       [0.43055084, 0.94666666],\n",
       "       [0.4278442 , 0.94666666],\n",
       "       [0.42518052, 0.94666666],\n",
       "       [0.42255855, 0.94666666],\n",
       "       [0.41997692, 0.94666666],\n",
       "       [0.41743448, 0.9533333 ],\n",
       "       [0.41493005, 0.9533333 ],\n",
       "       [0.4124625 , 0.9533333 ],\n",
       "       [0.4100308 , 0.9533333 ],\n",
       "       [0.40763393, 0.9533333 ],\n",
       "       [0.40527093, 0.9533333 ],\n",
       "       [0.40294084, 0.9533333 ],\n",
       "       [0.40064272, 0.9533333 ],\n",
       "       [0.39837584, 0.9533333 ],\n",
       "       [0.39613938, 0.9533333 ],\n",
       "       [0.39393246, 0.96      ],\n",
       "       [0.39175442, 0.96666664],\n",
       "       [0.38960448, 0.96666664],\n",
       "       [0.3874821 , 0.96666664]], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_history=fit(X_train=X,y_train=Y,num_epochs=100,lr=0.01,y_dummy=y_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
